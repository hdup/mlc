{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import linear_model, logistic_model, log_cost, log_cost_dev, gd_update\n",
    "from models import binary_confusion_matrix, std_normalize, binary_accuracy, create_parameters, data_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1), prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150 entries, 72 to 38\n",
      "Data columns (total 6 columns):\n",
      "Id               150 non-null int64\n",
      "SepalLengthCm    150 non-null float64\n",
      "SepalWidthCm     150 non-null float64\n",
      "PetalLengthCm    150 non-null float64\n",
      "PetalWidthCm     150 non-null float64\n",
      "Species          150 non-null object\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/iris.csv')\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>IsSetosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  IsSetosa\n",
       "72             6.3           2.5            4.9           1.5       0.0\n",
       "99             5.7           2.8            4.1           1.3       0.0\n",
       "21             5.1           3.7            1.5           0.4       1.0\n",
       "39             5.1           3.4            1.5           0.2       1.0\n",
       "147            6.5           3.0            5.2           2.0       0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IsSetosa'] = df['Species'].apply(lambda a: 1.0 if a=='Iris-setosa' else 0)\n",
    "data = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'IsSetosa']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_X = np.array(train[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']])\n",
    "train_y = np.array(train[['IsSetosa']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.87333333,  3.01833333,  3.82083333,  1.20833333])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stds, train_means = std_normalize(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.51250913e-16,   1.62832710e-15,   5.92118946e-17,\n",
       "         1.25825276e-16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(train_X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2), train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, cost: 1.3745801338925958, conf: (0.04477611940298507, 0.07894736842105263, 0.05714285714285714)\n",
      "epoch: 200, cost: 0.674898608867079, conf: (0.42105263157894735, 0.631578947368421, 0.5052631578947367)\n",
      "epoch: 300, cost: 0.4110166387166828, conf: (0.6379310344827587, 0.9736842105263158, 0.7708333333333335)\n",
      "epoch: 400, cost: 0.29126399010419846, conf: (0.7450980392156863, 1.0, 0.8539325842696629)\n",
      "epoch: 500, cost: 0.22517771606799214, conf: (0.8636363636363636, 1.0, 0.9268292682926829)\n",
      "epoch: 600, cost: 0.18350381003692745, conf: (0.9047619047619048, 1.0, 0.9500000000000001)\n",
      "epoch: 700, cost: 0.15485671561715814, conf: (0.95, 1.0, 0.9743589743589743)\n",
      "epoch: 800, cost: 0.13397360852104612, conf: (0.95, 1.0, 0.9743589743589743)\n",
      "epoch: 900, cost: 0.11809009119945889, conf: (1.0, 1.0, 1.0)\n",
      "epoch: 1000, cost: 0.10561324578302447, conf: (1.0, 1.0, 1.0)\n",
      "training finished!\n",
      "final cost: 0.10550201197717494, conf: (1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "feature_size = train_X.shape[1]\n",
    "sample_count = train_X.shape[0]\n",
    "\n",
    "W, b = create_parameters(feature_size)\n",
    "\n",
    "threshold = 0.5\n",
    "lr = 0.01\n",
    "\n",
    "for epoch in range(0, 1000):\n",
    "    h = logistic_model(train_X, W, b)\n",
    "    dW, db = log_cost_dev(train_X, train_y, h)\n",
    "    W, b = gd_update(W, b, dW, db, lr)\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        cur_cost = log_cost(h, train_y)\n",
    "        conf = binary_confusion_matrix(h, train_y, threshold=threshold)\n",
    "        print('epoch: {0}, cost: {1}, conf: {2}'.format(epoch + 1, cur_cost, conf))\n",
    "\n",
    "predictions = logistic_model(train_X, W, b)\n",
    "final_cost = log_cost(predictions, train_y)\n",
    "conf = binary_confusion_matrix(predictions, train_y, threshold=threshold)\n",
    "print('training finished!')\n",
    "print('final cost: {0}, conf: {1}'.format(final_cost, conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3). try test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = np.array(test[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']])\n",
    "test_y = np.array(test[['IsSetosa']])\n",
    "data_normalize(test_X, train_stds, train_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cost: 0.12952589901785055, conf: (0.9230769230769231, 1.0, 0.9600000000000001)\n"
     ]
    }
   ],
   "source": [
    "test_h = logistic_model(test_X, W, b)\n",
    "test_cost = log_cost(test_h, test_y)\n",
    "test_conf = binary_confusion_matrix(test_h, test_y, threshold=threshold)\n",
    "print('test cost: {0}, conf: {1}'.format(test_cost, test_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**so, this is only for Setosa, we want generalize binary classification to multi-classies**\n",
    "### Iris, one-vs-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1), prepare data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-setosa', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsSetosa'] = df['Species'].apply(lambda a: 1.0 if a=='Iris-setosa' else 0)\n",
    "df['IsVericolor'] = df['Species'].apply(lambda a: 1.0 if a=='Iris-versicolor' else 0)\n",
    "df['IsVirginica'] = df['Species'].apply(lambda a: 1.0 if a=='Iris-virginica' else 0)\n",
    "data = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'IsSetosa', 'IsVericolor', 'IsVirginica']]\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_X = np.array(train[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']])\n",
    "train_y0 = np.array(train[['IsSetosa']])\n",
    "train_y1 = np.array(train[['IsVericolor']])\n",
    "train_y2 = np.array(train[['IsVirginica']])\n",
    "train_y_all = np.array(train[['IsSetosa', 'IsVericolor', 'IsVirginica']])\n",
    "\n",
    "test_X = np.array(test[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']])\n",
    "test_y_all = np.array(test[['IsSetosa', 'IsVericolor', 'IsVirginica']])\n",
    "\n",
    "x_means, x_stds = std_normalize(train_X)\n",
    "data_normalize(test_X, x_means, x_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2), define some utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lr_classifier(X, y, lr=0.01, threshold=0.5, epochs=1000, step_size=100):\n",
    "    feature_size = X.shape[1]\n",
    "    sample_count = y.shape[0]\n",
    "    W, b = create_parameters(feature_size)\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        h = logistic_model(X, W, b)\n",
    "        dW, db = log_cost_dev(X, y, h)\n",
    "        W, b = gd_update(W, b, dW, db, lr)\n",
    "        if (epoch + 1) % step_size == 0:\n",
    "            cur_cost = log_cost(h, y)\n",
    "            conf = binary_confusion_matrix(h, y, threshold=threshold)\n",
    "            print('epoch: {0}, cost: {1}, conf: {2}'.format(epoch + 1, cur_cost, conf))\n",
    "\n",
    "    predictions = logistic_model(X, W, b)\n",
    "    final_cost = log_cost(predictions, y)\n",
    "    conf = binary_confusion_matrix(predictions, y, threshold=threshold)\n",
    "    print('training finished!')\n",
    "    print('final cost: {0}, conf: {1}'.format(final_cost, conf))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, cost: 0.6413593778580737, conf: (0.8333333333333334, 0.23255813953488372, 0.3636363636363636)\n",
      "epoch: 200, cost: 0.3239125928763921, conf: (0.9629629629629629, 0.6046511627906976, 0.7428571428571429)\n",
      "epoch: 300, cost: 0.19547085770561048, conf: (1.0, 0.8837209302325582, 0.9382716049382717)\n",
      "epoch: 400, cost: 0.136598131506859, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "epoch: 500, cost: 0.10514600594178773, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "epoch: 600, cost: 0.08612278759634744, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "epoch: 700, cost: 0.07351856281845054, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "epoch: 800, cost: 0.06459017480374314, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "epoch: 900, cost: 0.05794039815033709, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "epoch: 1000, cost: 0.052792391408487065, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n",
      "training finished!\n",
      "final cost: 0.05274675309628947, conf: (1.0, 0.9767441860465116, 0.988235294117647)\n"
     ]
    }
   ],
   "source": [
    "m0 = train_lr_classifier(train_X, train_y0, lr=0.01, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10000, cost: 0.4672810189697581, conf: (0.64, 0.43243243243243246, 0.5161290322580645)\n",
      "epoch: 20000, cost: 0.46612468084009984, conf: (0.64, 0.43243243243243246, 0.5161290322580645)\n",
      "epoch: 30000, cost: 0.4659093728560644, conf: (0.64, 0.43243243243243246, 0.5161290322580645)\n",
      "epoch: 40000, cost: 0.46579602875281123, conf: (0.64, 0.43243243243243246, 0.5161290322580645)\n",
      "epoch: 50000, cost: 0.46573324705435276, conf: (0.64, 0.43243243243243246, 0.5161290322580645)\n",
      "training finished!\n",
      "final cost: 0.46573324684480516, conf: (0.64, 0.43243243243243246, 0.5161290322580645)\n"
     ]
    }
   ],
   "source": [
    "m1 = train_lr_classifier(train_X, train_y1, lr=0.01, threshold=0.5, epochs=50000, step_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10000, cost: 0.12692241149644967, conf: (0.95, 0.95, 0.9500000000000001)\n",
      "epoch: 20000, cost: 0.09590092286288818, conf: (0.9512195121951219, 0.975, 0.9629629629629629)\n",
      "epoch: 30000, cost: 0.08151045623289317, conf: (0.9512195121951219, 0.975, 0.9629629629629629)\n",
      "epoch: 40000, cost: 0.07295167490350239, conf: (0.9512195121951219, 0.975, 0.9629629629629629)\n",
      "epoch: 50000, cost: 0.06715221727815238, conf: (0.9512195121951219, 0.975, 0.9629629629629629)\n",
      "training finished!\n",
      "final cost: 0.067151727629488, conf: (0.9512195121951219, 0.975, 0.9629629629629629)\n"
     ]
    }
   ],
   "source": [
    "m2 = train_lr_classifier(train_X, train_y2, lr=0.01, threshold=0.5, epochs=50000, step_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify multi-class with Softmax\n",
    "\n",
    "What is softmax?\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Softmax(x_j) = \\frac{e^{x_j}}{\\sum_{i=1}^m e^{x_{i}}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "See details in models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10000, cost: 0.040805551375077395, acc: 0.975\n",
      "epoch: 20000, cost: 0.02969192477577395, acc: 0.975\n",
      "epoch: 30000, cost: 0.02494988618992539, acc: 0.975\n",
      "epoch: 40000, cost: 0.02219898562705884, acc: 0.9833333333333333\n",
      "epoch: 50000, cost: 0.020356746091358142, acc: 0.9833333333333333\n",
      "epoch: 60000, cost: 0.019015789622029135, acc: 0.9833333333333333\n",
      "epoch: 70000, cost: 0.01798504255574665, acc: 0.9833333333333333\n",
      "epoch: 80000, cost: 0.017161654145229403, acc: 0.9833333333333333\n",
      "epoch: 90000, cost: 0.016484771512794216, acc: 0.9833333333333333\n",
      "epoch: 100000, cost: 0.01591581752130277, acc: 0.9833333333333333\n",
      "training finished!\n",
      "train cost: 0.015915765086367127, acc: 0.9833333333333333\n",
      "test cost: 0.026905784702824006, acc: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "feature_size = train_X.shape[1]\n",
    "sample_count = train_X.shape[0]\n",
    "class_count = train_y_all.shape[1]\n",
    "\n",
    "W, b = ml.create_parameters(feature_size, class_count)\n",
    "\n",
    "for epoch in range(0, 100000):\n",
    "    h = ml.softmax_regression_model(train_X, W, b)\n",
    "    dW, db = ml.crossentropy_cost_dev(train_X, train_y_all, h)\n",
    "    W, b = ml.gd_update(W, b, dW, db, lr=0.01)\n",
    "    if (epoch + 1) % 10000 == 0:\n",
    "        cur_cost = ml.crossentropy_cost(h, train_y_all)\n",
    "        cur_acc = ml.categorical_accuracy(h, train_y_all)\n",
    "        print('epoch: {0}, cost: {1}, acc: {2}'.format(epoch + 1, cur_cost, cur_acc))\n",
    "\n",
    "predictions = ml.softmax_regression_model(train_X, W, b)\n",
    "final_cost = ml.crossentropy_cost(predictions, train_y_all)\n",
    "final_acc = ml.categorical_accuracy(predictions, train_y_all)\n",
    "print('training finished!')\n",
    "print('train cost: {0}, acc: {1}'.format(final_cost, final_acc))\n",
    "\n",
    "test_h = ml.softmax_regression_model(test_X, W, b)\n",
    "test_cost = ml.crossentropy_cost(test_h, test_y_all)\n",
    "test_acc = ml.categorical_accuracy(test_h, test_y_all)\n",
    "print('test cost: {0}, acc: {1}'.format(test_cost, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import models as ml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import mnist_reader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1), load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('./data/data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('./data/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (X_train.reshape((X_train.shape[0], 28, 28, 1)) / 255.0).astype(np.float32)\n",
    "X_test = (X_test.reshape((X_test.shape[0], 28, 28, 1)) / 255.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id_to_onehot(y, size):\n",
    "    onehot = np.zeros(shape=(y.shape[0], size))\n",
    "    for i in range(0, y.shape[0]):\n",
    "        onehot[i][y[i]] = 1\n",
    "    return onehot\n",
    "\n",
    "def show_img(img, zoom=4, dpi=80):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    plt.figure(figsize=(w*zoom/dpi, h*zoom/dpi), dpi=dpi)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJcAAACZCAYAAAAilagJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ea09e87748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(X_train[234].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = id_to_onehot(y_train, 10)\n",
    "y_test = id_to_onehot(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2), build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 27, 27, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 27, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                23050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 31,890\n",
      "Trainable params: 31,678\n",
      "Non-trainable params: 212\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "\n",
    "m.add(Convolution2D(filters=32, kernel_size=(2, 2), strides=(1, 1), padding='valid', input_shape=(28, 28, 1)))\n",
    "m.add(BatchNormalization())\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "m.add(Convolution2D(filters=64, kernel_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "m.add(BatchNormalization())\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "m.add(Flatten())\n",
    "m.add(Dense(10))\n",
    "m.add(BatchNormalization())\n",
    "m.add(Activation('softmax'))\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.compile(optimizer='Adam',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.3560 - acc: 0.8838 - val_loss: 0.2763 - val_acc: 0.9007\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 42s - loss: 0.3280 - acc: 0.8936 - val_loss: 0.2566 - val_acc: 0.9098\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.3112 - acc: 0.8981 - val_loss: 0.2518 - val_acc: 0.9126\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.3039 - acc: 0.9009 - val_loss: 0.2463 - val_acc: 0.9129\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.2998 - acc: 0.9014 - val_loss: 0.2577 - val_acc: 0.9134\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.2860 - acc: 0.9078 - val_loss: 0.2463 - val_acc: 0.9161\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.2827 - acc: 0.9063 - val_loss: 0.2475 - val_acc: 0.9143\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 42s - loss: 0.2701 - acc: 0.9116 - val_loss: 0.2487 - val_acc: 0.9140\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.2699 - acc: 0.9123 - val_loss: 0.2388 - val_acc: 0.9191\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.2614 - acc: 0.9139 - val_loss: 0.2413 - val_acc: 0.9159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e69ea23e48>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train,\n",
    "      y_train,\n",
    "      validation_data=(X_test, y_test),\n",
    "      batch_size=10,\n",
    "      epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_test = m.evaluate(X_train, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1520828681305051, accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "print('loss: {0}, accuracy: {1}'.format(evaluation_test[0], evaluation_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a), let's use ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#resize image\n",
    "cv2.resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshape data into 3-channel tensor\n",
    "train_X_3d = train_X.reshape((train_X.shape[0], 28, 28, 1)) * np.ones(3, dtype=np.float32)[None, None, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 197x197, got `input_shape=(28, 28, 3)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-32f1cfcbbcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                        \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                        include_top=False)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\evitself\\Anaconda3\\lib\\site-packages\\keras\\applications\\resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    190\u001b[0m                                       \u001b[0mmin_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m197\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                                       include_top=include_top)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\evitself\\Anaconda3\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, include_top)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     raise ValueError('Input size must be at least ' +\n\u001b[1;32m    134\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'x'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', got '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input size must be at least 197x197, got `input_shape=(28, 28, 3)`"
     ]
    }
   ],
   "source": [
    "rm = ResNet50(input_shape=(197, 197, 3), \n",
    "              classes=10, \n",
    "              weights=None, \n",
    "              include_top=False)\n",
    "\n",
    "rm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3), have fun with our softmax model implemented with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_count = 28 * 28\n",
    "sample_count = X_train.shape[0]\n",
    "\n",
    "train_X = X_train.reshape((sample_count, feature_count))\n",
    "test_X = X_test.reshape((X_test.shape[0], feature_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size=20\n",
    "step = 10\n",
    "\n",
    "W, b = ml.create_parameters(feature_count, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, cost 0.09119493406200503, acc 0.7713333333333333\n",
      "epoch 20, cost 0.07384588485744492, acc 0.7983\n",
      "epoch 30, cost 0.06548564852534794, acc 0.8121\n",
      "epoch 40, cost 0.06027913865292422, acc 0.82045\n",
      "epoch 50, cost 0.056615567307002734, acc 0.8271166666666666\n",
      "epoch 60, cost 0.05384892012732094, acc 0.8324166666666667\n",
      "epoch 70, cost 0.0516660877644781, acc 0.8360666666666666\n",
      "epoch 80, cost 0.04989212593012495, acc 0.8398666666666667\n",
      "epoch 90, cost 0.04841893529651631, acc 0.8428\n",
      "epoch 100, cost 0.04717511573885371, acc 0.8458333333333333\n",
      "training finished.\n",
      "final cost 0.04717511573885371, acc 0.8458333333333333\n",
      "test cost 0.055191518140006834, acc 0.8293\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs):\n",
    "\n",
    "    batch_start = 0    \n",
    "    while(batch_start + batch_size < sample_count):\n",
    "        batch_X = train_X[batch_start:batch_start+batch_size,:]\n",
    "        batch_y = y_train[batch_start:batch_start+batch_size,:] \n",
    "        h = ml.softmax_regression_model(batch_X, W, b)\n",
    "        dW, db = ml.crossentropy_cost_dev(batch_X, batch_y, h)\n",
    "        W, b = ml.gd_update(W, b, dW, db, lr=0.01)\n",
    "        batch_start += batch_size\n",
    "\n",
    "    if (epoch + 1) % step == 0:\n",
    "        h = ml.softmax_regression_model(train_X, W, b)\n",
    "        cost = ml.crossentropy_cost(h, y_train)\n",
    "        acc = ml.categorical_accuracy(h, y_train)\n",
    "        print(\"epoch {0}, cost {1}, acc {2}\".format(epoch + 1, cost, acc))\n",
    "\n",
    "print(\"training finished.\")        \n",
    "        \n",
    "h = ml.softmax_regression_model(train_X, W, b)\n",
    "cost = ml.crossentropy_cost(h, y_train)\n",
    "acc = ml.categorical_accuracy(h, y_train)\n",
    "print(\"final cost {0}, acc {1}\".format(cost, acc))\n",
    "\n",
    "h = ml.softmax_regression_model(test_X, W, b)\n",
    "cost = ml.crossentropy_cost(h, y_test)\n",
    "acc = ml.categorical_accuracy(h, y_test)\n",
    "print(\"test cost {0}, acc {1}\".format(cost, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
